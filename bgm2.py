import requests
import csv
import math
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# ================= é…ç½® =================

USER_ID = 888347
API_BASE = "https://api.bgm.tv"
OUTPUT_CSV = "bangumi_result.csv"
ACCESS_TOKEN = "kBgUZMutEmPoyYqgOX0zmxSN4qh9Jg3NpgCffc9V"

HEADERS = {
    "User-Agent": "12819/bgm-collection-fetcher (private-script)",
    "Accept": "application/json",
    "Authorization": f"Bearer {ACCESS_TOKEN}"
}

MAX_WORKERS = 9   # å¹¶å‘æ•°ï¼Œ6~10 æ¯”è¾ƒå®‰å…¨
REQUEST_DELAY = 0.1  # é˜²æ­¢è¿‡å¿«ï¼ˆç§’ï¼‰

# ========================================

session = requests.Session()
session.headers.update(HEADERS)


def get_all_subject_ids(user_id):
    """é€šè¿‡ API è·å–ç”¨æˆ·æ‰€æœ‰æ”¶è—çš„ subject_id"""
    subject_ids = []
    offset = 0
    limit = 30

    while True:
        url = f"{API_BASE}/v0/users/{user_id}/collections"
        params = {
            "type": 2,
            "limit": limit,
            "offset": offset
        }

        r = session.get(url, params=params, timeout=10)
        if r.status_code == 400:
            print("ğŸ“Œ offset åˆ°å¤´ï¼Œæ”¶è—åˆ—è¡¨è·å–å®Œæ¯•")
            break
        r.raise_for_status()
        data = r.json()

        if not data.get("data"):
            break

        for item in data["data"]:
            subject = item.get("subject", {})
            if subject.get("type") == 2: #1 ä¸º ä¹¦ç±,2 ä¸º åŠ¨ç”»,3 ä¸º éŸ³ä¹,4 ä¸º æ¸¸æˆ,6 ä¸º ä¸‰æ¬¡å…ƒ
                subject_ids.append(item["subject_id"])

        offset += limit
        time.sleep(REQUEST_DELAY)

    return subject_ids


def calc_mean_std(counts: dict):
    """
    æ ¹æ®è¯„åˆ†åˆ†å¸ƒè®¡ç®—å¹³å‡åˆ†å’Œæ ‡å‡†å·®
    counts: {"1": 12, "2": 34, ..., "10": 56}
    """
    total = sum(counts.values())
    if total == 0:
        return None, None

    mean = sum(int(k) * v for k, v in counts.items()) / total
    var = sum(v * (int(k) - mean) ** 2 for k, v in counts.items()) / total
    std = math.sqrt(var)

    return mean, std


def fetch_subject(subject_id):
    """è·å–å•ä¸ª subject çš„ä¿¡æ¯å¹¶è®¡ç®—"""
    url = f"{API_BASE}/v0/subjects/{subject_id}"

    try:
        r = session.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()

        name = data.get("name_cn") or data.get("name")
        rating = data.get("rating", {})
        counts = rating.get("count", {})

        mean, std = calc_mean_std(counts)
        if mean is None:
            return None

        return {
            "name": name,
            "mean": round(mean, 3),
            "std": round(std, 3),
            "subject_id": subject_id
        }

    except Exception as e:
        print(f"âŒ subject {subject_id} å¤±è´¥ï¼š{e}")
        return None


def main():
    print("ğŸ“¥ è·å–æ”¶è—åˆ—è¡¨ä¸­...")
    subject_ids = get_all_subject_ids(USER_ID)
    print(f"âœ” å…±æ‰¾åˆ° {len(subject_ids)} ä¸ª subject")

    results = []

    print("ğŸš€ å¹¶å‘è®¡ç®—ä¸­...")
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:
        futures = [pool.submit(fetch_subject, sid) for sid in subject_ids]

        for f in as_completed(futures):
            res = f.result()
            if res:
                results.append(res)

    if not results:
        print("âš  æ— æˆåŠŸæ•°æ®ï¼Œæœªç”Ÿæˆ CSV")
        return

    print(f"ğŸ’¾ å†™å…¥ CSVï¼š{OUTPUT_CSV}")
    with open(OUTPUT_CSV, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=["name", "mean", "std", "subject_id"]
        )
        writer.writeheader()
        writer.writerows(results)

    print("âœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
